{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV7MPOefwFG2tf3n/W2Cpu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ferstuque/VoiceControl/blob/main/Text_to_audio___audio_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio to Text and Text to Audio Notebook"
      ],
      "metadata": {
        "id": "PHhRTBlY2xx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is based on the Carleslc Notebook. You can find the original and complete version at [LINK](https://github.com/Carleslc/AudioToText?tab=readme-ov-file)\n",
        "\n",
        "‚ö†Ô∏è For faster processing, consider running this Notebook on a GPU.\n",
        "\n",
        "[Whisper by OpenAI](https://github.com/openai/whisper)"
      ],
      "metadata": {
        "id": "a8dSAuCV1Wqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by installing the necessary dependencies for this notebook."
      ],
      "metadata": {
        "id": "c2ihWNV-3Lou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "import subprocess\n",
        "\n",
        "from sys import platform as sys_platform\n",
        "\n",
        "status, ffmpeg_version = subprocess.getstatusoutput(\"ffmpeg -version\")\n",
        "\n",
        "if status != 0:\n",
        "  from platform import platform\n",
        "\n",
        "  if sys_platform == 'linux' and 'ubuntu' in platform().lower():\n",
        "    !apt install ffmpeg\n",
        "  else:\n",
        "    print(\"Install ffmpeg: https://ffmpeg.org/download.html\")\n",
        "else:\n",
        "  print(ffmpeg_version.split('\\n')[0])\n",
        "\n",
        "  NO_ROOT_WARNING = '|& grep -v \\\"WARNING: Running pip as the \\'root\\' user\"' # running in Colab\n",
        "\n",
        "  !pip install --no-warn-script-location --user --upgrade pip {NO_ROOT_WARNING}\n",
        "  !pip install --root-user-action=ignore git+https://github.com/openai/whisper.git@v20231117 openai==1.9.0 numpy scipy deepl pydub cohere ffmpeg-python torch==2.1.0 tensorflow-probability==0.23.0 typing-extensions==4.9.0\n",
        "  !pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsQOtX3dsVCI",
        "outputId": "2873e72b-b1f6-4c2c-b057-5021cd13b08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "Requirement already satisfied: pip in /root/.local/lib/python3.11/site-packages (25.0)\n",
            "Collecting git+https://github.com/openai/whisper.git@v20231117\n",
            "  Cloning https://github.com/openai/whisper.git (to revision v20231117) to /tmp/pip-req-build-vc3sayfb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-vc3sayfb\n",
            "  Running command git checkout -q e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai==1.9.0 in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: deepl in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.11/dist-packages (5.13.11)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: tensorflow-probability==0.23.0 in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: typing-extensions==4.9.0 in /usr/local/lib/python3.11/dist-packages (4.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.9.0) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (1.17.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.23.0) (0.1.8)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.6.85)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20231117) (0.8.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from deepl) (2.32.3)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere) (1.10.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.23.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.9.0) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.9.0) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.9.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.9.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.9.0) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->deepl) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->deepl) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20231117) (2024.11.6)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2024.12.14)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to audio"
      ],
      "metadata": {
        "id": "-n9hjKkirV63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click ‚ñ∂Ô∏è button below and write your text\n",
        "from gtts import gTTS\n",
        "input_text = input()\n",
        "text_to_say = input_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "sJvx7xzNg_83",
        "outputId": "0dcbded5-432e-4b8a-a727-c4856e1a3d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hallo, wie geht es dir?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Now, select your language before run this cell\n",
        "\n",
        "language = \"de\" #@param [\"af\", \"sq\", \"am\", \"ar\", \"hy\", \"as\", \"az\", \"ba\", \"eu\", \"be\", \"bn\", \"bs\", \"br\", \"bg\", \"my\", \"es\", \"ca\", \"zh\", \"hr\", \"cs\", \"da\", \"nl\", \"en\", \"et\", \"fo\", \"fi\", \"nl\", \"fr\", \"gl\", \"ka\", \"de\", \"el\", \"gu\", \"ht\", \"ht\", \"ha\", \"ha\", \"he\", \"hi\", \"hu\", \"is\", \"id\", \"it\", \"ja\", \"jv\", \"kn\", \"kk\", \"km\", \"ko\", \"lo\", \"la\", \"lv\", \"lb\", \"ln\", \"lt\", \"lb\", \"mk\", \"mg\", \"ms\", \"ml\", \"mt\", \"mi\", \"mr\", \"ro\", \"ro\", \"mn\", \"my\", \"ne\", \"no\", \"nn\", \"oc\", \"pa\", \"ps\", \"fa\", \"pl\", \"pt\", \"pa\", \"ps\", \"ro\", \"ru\", \"sa\", \"sr\", \"sn\", \"sd\", \"si\", \"si\", \"sk\", \"sl\", \"so\", \"es\", \"su\", \"sw\", \"sv\", \"tl\", \"tg\", \"ta\", \"tt\", \"te\", \"th\", \"bo\", \"tr\", \"tk\", \"uk\", \"ur\", \"uz\", \"ca\", \"vi\", \"cy\", \"yi\", \"yo\"]\n",
        "\n",
        "gtts_object = gTTS(text = text_to_say,\n",
        "                  lang = language,\n",
        "                  slow = False)\n",
        "\n",
        "gtts_object.save(\"/content/gtts.wav\")\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "Audio(\"/content/gtts.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "cellView": "form",
        "id": "-Js9tHdMleac",
        "outputId": "15dc0f39-20d6-419d-aaf4-068fb05e415f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio to Text"
      ],
      "metadata": {
        "id": "9WWMkvVz0R6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this session an AI can detect your language to trancribe it to text.\n",
        "\n",
        "\n",
        "**Task:** Choose an action, Transcribe or Translate your previous audio recording.\n",
        "\n",
        "**Use Module:** If the execution time is excessive, consider using a smaller model in `use_model`. This may result in a slight decrease in accuracy, but can improve performance. Alternatively, you can utilize the OpenAI API.\n",
        "\n",
        "**Language:** Choose your language from the list or select \"Auto-Detect\" to have your recorded file processed automatically.\n",
        "\n",
        "**Prompt:** You can add an optional initial prompt to provide context about the audio or to guide the AI towards a specific writing style. Refer to the prompting [guide](https://platform.openai.com/docs/guides/speech-to-text/prompting) for more information.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pmu14w3QwCRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Record your audio and save it\n",
        "# This cell code is a slightly modified version of DotCSV code in the following Colab along with other references:\n",
        "# https://colab.research.google.com/drive/1CvvYPAFemIZdSOt9fhN541esSlZR7Ic6?usp=sharing\n",
        "\n",
        "try:\n",
        "  import io\n",
        "  import os\n",
        "  import ffmpeg\n",
        "  import numpy as np\n",
        "\n",
        "  # Only available in Google Colab\n",
        "  from google.colab.output import eval_js\n",
        "\n",
        "  from IPython.display import HTML, Audio\n",
        "  from scipy.io.wavfile import write, read as wav_read\n",
        "  from base64 import b64decode\n",
        "  from os.path import isfile\n",
        "\n",
        "  AUDIO_HTML = \"\"\"\n",
        "  <script>\n",
        "  var my_div = document.createElement(\"DIV\");\n",
        "  var my_p = document.createElement(\"P\");\n",
        "  var my_btn = document.createElement(\"BUTTON\");\n",
        "  var t = document.createTextNode(\"Starting recording...\");\n",
        "\n",
        "  my_btn.appendChild(t);\n",
        "  my_div.appendChild(my_btn);\n",
        "  document.body.appendChild(my_div);\n",
        "\n",
        "  var base64data = 0;\n",
        "  var reader;\n",
        "  var recorder, gumStream;\n",
        "  var recordButton = my_btn;\n",
        "\n",
        "  var handleSuccess = function(stream) {\n",
        "    gumStream = stream;\n",
        "    var options = {\n",
        "      bitsPerSecond: 16000,\n",
        "      mimeType : 'audio/webm;codecs=opus' //codecs=pcm\n",
        "    };\n",
        "    recorder = new MediaRecorder(stream, options);\n",
        "    //recorder = new MediaRecorder(stream);\n",
        "\n",
        "    recorder.ondataavailable = function(e) {\n",
        "      var url = URL.createObjectURL(e.data);\n",
        "      var preview = document.createElement('audio');\n",
        "      preview.controls = true;\n",
        "      preview.src = url;\n",
        "      document.body.appendChild(preview);\n",
        "\n",
        "      reader = new FileReader();\n",
        "      reader.readAsDataURL(e.data);\n",
        "      reader.onloadend = function() {\n",
        "        base64data = reader.result;\n",
        "        //console.log(\"reader.onloadend: \" + base64data);\n",
        "      }\n",
        "    };\n",
        "    recorder.start();\n",
        "    recordButton.innerText = \"üî¥ Recording... press to STOP\";\n",
        "  };\n",
        "\n",
        "  navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "  function toggleRecording() {\n",
        "    if (recorder && recorder.state == \"recording\") {\n",
        "        recorder.stop();\n",
        "        gumStream.getAudioTracks()[0].stop();\n",
        "        recordButton.innerText = \"Saving the recording... please wait!\";\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // https://stackoverflow.com/a/951057\n",
        "  function sleep(ms) {\n",
        "    return new Promise(resolve => setTimeout(resolve, ms));\n",
        "  }\n",
        "\n",
        "  var data = new Promise(resolve => {\n",
        "    recordButton.onclick = () => {\n",
        "      toggleRecording();\n",
        "\n",
        "      sleep(2000).then(() => {\n",
        "        // wait 2000ms for the data to be available...\n",
        "        //console.log(\"resolve data: \" + base64data);\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  });\n",
        "\n",
        "  function doneRecording(recording_file) {\n",
        "    my_div.removeChild(recordButton);\n",
        "    my_p.innerText = recording_file;\n",
        "    my_div.appendChild(my_p);\n",
        "  }\n",
        "\n",
        "  </script>\n",
        "  \"\"\"\n",
        "\n",
        "  def get_audio():\n",
        "    display(HTML(AUDIO_HTML))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    process = (ffmpeg\n",
        "      .input('pipe:0')\n",
        "      .output('pipe:1', format='wav')\n",
        "      .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "    )\n",
        "    output, err = process.communicate(input=binary)\n",
        "\n",
        "    riff_chunk_size = len(output) - 8\n",
        "    # Break up the chunk size into four bytes, held in b.\n",
        "    q = riff_chunk_size\n",
        "    b = []\n",
        "    for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "    # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "    riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "    sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "    return audio, sr\n",
        "\n",
        "  recording_file = \"recording.wav\" #@param {type:\"string\"}\n",
        "\n",
        "  if isfile(recording_file):\n",
        "    print(f\"{recording_file} File name already exists. You can either create another recording with a different name, or delete the existing file first.\")\n",
        "  else:\n",
        "    # record microphone\n",
        "    audio, sr = get_audio()\n",
        "\n",
        "    # write recording\n",
        "    write(recording_file, sr, audio)\n",
        "\n",
        "    eval_js(f'doneRecording(\"{recording_file}\")')\n",
        "except ImportError:\n",
        "  print(\"Recording only available in Google Colab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "cellView": "form",
        "id": "JlkOKRnsrT_7",
        "outputId": "648a45fc-6afe-4448-920f-d460a7ecf67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <script>\n",
              "  var my_div = document.createElement(\"DIV\");\n",
              "  var my_p = document.createElement(\"P\");\n",
              "  var my_btn = document.createElement(\"BUTTON\");\n",
              "  var t = document.createTextNode(\"Starting recording...\");\n",
              "\n",
              "  my_btn.appendChild(t);\n",
              "  my_div.appendChild(my_btn);\n",
              "  document.body.appendChild(my_div);\n",
              "\n",
              "  var base64data = 0;\n",
              "  var reader;\n",
              "  var recorder, gumStream;\n",
              "  var recordButton = my_btn;\n",
              "\n",
              "  var handleSuccess = function(stream) {\n",
              "    gumStream = stream;\n",
              "    var options = {\n",
              "      bitsPerSecond: 16000,\n",
              "      mimeType : 'audio/webm;codecs=opus' //codecs=pcm\n",
              "    };\n",
              "    recorder = new MediaRecorder(stream, options);\n",
              "    //recorder = new MediaRecorder(stream);\n",
              "\n",
              "    recorder.ondataavailable = function(e) {\n",
              "      var url = URL.createObjectURL(e.data);\n",
              "      var preview = document.createElement('audio');\n",
              "      preview.controls = true;\n",
              "      preview.src = url;\n",
              "      document.body.appendChild(preview);\n",
              "\n",
              "      reader = new FileReader();\n",
              "      reader.readAsDataURL(e.data);\n",
              "      reader.onloadend = function() {\n",
              "        base64data = reader.result;\n",
              "        //console.log(\"reader.onloadend: \" + base64data);\n",
              "      }\n",
              "    };\n",
              "    recorder.start();\n",
              "    recordButton.innerText = \"üî¥ Recording... press to STOP\";\n",
              "  };\n",
              "\n",
              "  navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "  function toggleRecording() {\n",
              "    if (recorder && recorder.state == \"recording\") {\n",
              "        recorder.stop();\n",
              "        gumStream.getAudioTracks()[0].stop();\n",
              "        recordButton.innerText = \"Saving the recording... please wait!\";\n",
              "    }\n",
              "  }\n",
              "\n",
              "  // https://stackoverflow.com/a/951057\n",
              "  function sleep(ms) {\n",
              "    return new Promise(resolve => setTimeout(resolve, ms));\n",
              "  }\n",
              "\n",
              "  var data = new Promise(resolve => {\n",
              "    recordButton.onclick = () => {\n",
              "      toggleRecording();\n",
              "\n",
              "      sleep(2000).then(() => {\n",
              "        // wait 2000ms for the data to be available...\n",
              "        //console.log(\"resolve data: \" + base64data);\n",
              "        resolve(base64data.toString());\n",
              "      });\n",
              "    }\n",
              "  });\n",
              "\n",
              "  function doneRecording(recording_file) {\n",
              "    my_div.removeChild(recordButton);\n",
              "    my_p.innerText = recording_file;\n",
              "    my_div.appendChild(my_p);\n",
              "  }\n",
              "\n",
              "  </script>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import format_timestamp, get_writer, WriteTXT\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "import torch\n",
        "\n",
        "import math\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# select task\n",
        "\n",
        "task = \"Translate to English\" #@param [\"Transcribe\", \"Translate to English\"]\n",
        "\n",
        "task = \"transcribe\" if task == \"Transcribe\" else \"translate\"\n",
        "\n",
        "# select audio file\n",
        "\n",
        "audio_file = recording_file\n",
        "\n",
        "audio_files = list(map(lambda audio_path: audio_path.strip(), audio_file.split(',')))\n",
        "\n",
        "for audio_path in audio_files:\n",
        "  if not os.path.isfile(audio_path):\n",
        "    raise FileNotFoundError(audio_path)\n",
        "\n",
        "# set model\n",
        "\n",
        "use_model = \"small\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n",
        "\n",
        "# select language\n",
        "\n",
        "language = \"Auto-Detect\" #@param [\"Auto-Detect\", \"Afrikaans\", \"Albanian\", \"Amharic\", \"Arabic\", \"Armenian\", \"Assamese\", \"Azerbaijani\", \"Bashkir\", \"Basque\", \"Belarusian\", \"Bengali\", \"Bosnian\", \"Breton\", \"Bulgarian\", \"Burmese\", \"Castilian\", \"Catalan\", \"Chinese\", \"Croatian\", \"Czech\", \"Danish\", \"Dutch\", \"English\", \"Estonian\", \"Faroese\", \"Finnish\", \"Flemish\", \"French\", \"Galician\", \"Georgian\", \"German\", \"Greek\", \"Gujarati\", \"Haitian\", \"Haitian Creole\", \"Hausa\", \"Hawaiian\", \"Hebrew\", \"Hindi\", \"Hungarian\", \"Icelandic\", \"Indonesian\", \"Italian\", \"Japanese\", \"Javanese\", \"Kannada\", \"Kazakh\", \"Khmer\", \"Korean\", \"Lao\", \"Latin\", \"Latvian\", \"Letzeburgesch\", \"Lingala\", \"Lithuanian\", \"Luxembourgish\", \"Macedonian\", \"Malagasy\", \"Malay\", \"Malayalam\", \"Maltese\", \"Maori\", \"Marathi\", \"Moldavian\", \"Moldovan\", \"Mongolian\", \"Myanmar\", \"Nepali\", \"Norwegian\", \"Nynorsk\", \"Occitan\", \"Panjabi\", \"Pashto\", \"Persian\", \"Polish\", \"Portuguese\", \"Punjabi\", \"Pushto\", \"Romanian\", \"Russian\", \"Sanskrit\", \"Serbian\", \"Shona\", \"Sindhi\", \"Sinhala\", \"Sinhalese\", \"Slovak\", \"Slovenian\", \"Somali\", \"Spanish\", \"Sundanese\", \"Swahili\", \"Swedish\", \"Tagalog\", \"Tajik\", \"Tamil\", \"Tatar\", \"Telugu\", \"Thai\", \"Tibetan\", \"Turkish\", \"Turkmen\", \"Ukrainian\", \"Urdu\", \"Uzbek\", \"Valencian\", \"Vietnamese\", \"Welsh\", \"Yiddish\", \"Yoruba\"]\n",
        "\n",
        "# other parameters\n",
        "\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "coherence_preference = \"More coherence, but may repeat text\" #@param [\"More coherence, but may repeat text\", \"Less repetitions, but may have less coherence\"]\n",
        "\n",
        "api_key = ''\n",
        "\n",
        "# detect device\n",
        "\n",
        "if api_key:\n",
        "  print(\"Using API\")\n",
        "\n",
        "  from pydub import AudioSegment\n",
        "  from pydub.silence import split_on_silence\n",
        "else:\n",
        "  DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  print(f\"Using {'GPU' if DEVICE == 'cuda' else 'CPU ‚ö†Ô∏è'}\")\n",
        "\n",
        "  # https://medium.com/analytics-vidhya/the-google-colab-system-specification-check-69d159597417\n",
        "  if DEVICE == \"cuda\":\n",
        "    !nvidia-smi -L\n",
        "  else:\n",
        "    if sys_platform == 'linux':\n",
        "      !lscpu | grep \"Model name\" | awk '{$1=$1};1'\n",
        "\n",
        "    print(\"Not using GPU can result in a very slow execution\")\n",
        "    print(\"Ensure Hardware accelerator by GPU is enabled in Google Colab: Runtime > Change runtime type\")\n",
        "\n",
        "    if use_model not in ['tiny', 'base', 'small']:\n",
        "      print(\"You may also want to try a smaller model (tiny, base, small)\")\n",
        "\n",
        "# display language\n",
        "\n",
        "WHISPER_LANGUAGES = [k.title() for k in whisper.tokenizer.TO_LANGUAGE_CODE.keys()]\n",
        "\n",
        "if language == \"Auto-Detect\":\n",
        "  language = \"detect\"\n",
        "\n",
        "if language and language != \"detect\" and language not in WHISPER_LANGUAGES:\n",
        "  print(f\"\\nLanguage '{language}' is invalid\")\n",
        "  language = \"detect\"\n",
        "\n",
        "if language and language != \"detect\":\n",
        "  print(f\"\\nLanguage: {language}\")\n",
        "\n",
        "# load model\n",
        "\n",
        "if api_key:\n",
        "  print()\n",
        "else:\n",
        "  MODELS_WITH_ENGLISH_VERSION = [\"tiny\", \"base\", \"small\", \"medium\"]\n",
        "\n",
        "  if language == \"English\" and use_model in MODELS_WITH_ENGLISH_VERSION:\n",
        "    use_model += \".en\"\n",
        "\n",
        "  print(f\"\\nLoading {use_model} model... {os.path.expanduser(f'~/.cache/whisper/{use_model}.pt')}\")\n",
        "\n",
        "  model = whisper.load_model(use_model, device=DEVICE)\n",
        "\n",
        "  print(\n",
        "      f\"Model {use_model} is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "      f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,d} parameters.\\n\"\n",
        "  )\n",
        "\n",
        "# set options\n",
        "\n",
        "## https://github.com/openai/whisper/blob/v20231117/whisper/transcribe.py#L37\n",
        "## https://github.com/openai/whisper/blob/v20231117/whisper/decoding.py#L81\n",
        "options = {\n",
        "    'task': task,\n",
        "    'verbose': True,\n",
        "    'fp16': True,\n",
        "    'best_of': 5,\n",
        "    'beam_size': 5,\n",
        "    'patience': None,\n",
        "    'length_penalty': None,\n",
        "    'suppress_tokens': '-1',\n",
        "    'temperature': (0.0, 0.2, 0.4, 0.6, 0.8, 1.0), # float or tuple\n",
        "    'condition_on_previous_text': coherence_preference == \"More coherence, but may repeat text\",\n",
        "    'initial_prompt': prompt or None,\n",
        "    'word_timestamps': False,\n",
        "}\n",
        "\n",
        "if api_key:\n",
        "  api_client = OpenAI(api_key=api_key)\n",
        "\n",
        "  api_supported_formats = ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm']\n",
        "  api_max_bytes = 25 * 1024 * 1024 # 25 MB\n",
        "\n",
        "  api_transcribe = api_client.audio.transcriptions if task == 'transcribe' else api_client.audio.translations\n",
        "  api_transcribe = api_transcribe.create\n",
        "\n",
        "  api_model = 'whisper-1' # large-v2\n",
        "\n",
        "  # https://platform.openai.com/docs/api-reference/audio?lang=python\n",
        "  api_options = {\n",
        "    'response_format': 'verbose_json',\n",
        "  }\n",
        "\n",
        "  if prompt:\n",
        "    api_options['prompt'] = prompt\n",
        "\n",
        "  api_temperature = options['temperature'][0] if isinstance(options['temperature'], (tuple, list)) else options['temperature']\n",
        "\n",
        "  if isinstance(api_temperature, (float, int)):\n",
        "    api_options['temperature'] = api_temperature\n",
        "  else:\n",
        "    raise ValueError(\"Invalid temperature type, it must be a float or a tuple of floats\")\n",
        "elif DEVICE == 'cpu':\n",
        "  options['fp16'] = False\n",
        "  torch.set_num_threads(os.cpu_count())\n",
        "\n",
        "# execute task\n",
        "# !whisper \"{audio_file}\" --task {task} --model {use_model} --output_dir {output_dir} --device {DEVICE} --verbose {options['verbose']}\n",
        "\n",
        "if task == \"translate\":\n",
        "  print(\"-- TRANSLATE TO ENGLISH --\")\n",
        "else:\n",
        "  print(\"-- TRANSCRIPTION --\")\n",
        "\n",
        "results = {} # audio_path to result\n",
        "\n",
        "for audio_path in audio_files:\n",
        "  print(f\"\\nProcessing: {audio_path}\\n\")\n",
        "\n",
        "  # detect language\n",
        "  detect_language = not language or language == \"detect\"\n",
        "\n",
        "  if not detect_language:\n",
        "    options['language'] = language\n",
        "    source_language_code = whisper.tokenizer.TO_LANGUAGE_CODE.get(language.lower())\n",
        "  elif not api_key:\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio_path)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "\n",
        "    source_language_code = max(probs, key=probs.get)\n",
        "    options['language'] = whisper.tokenizer.LANGUAGES[source_language_code].title()\n",
        "\n",
        "    print(f\"Detected language: {options['language']}\\n\")\n",
        "\n",
        "  # transcribe\n",
        "  if api_key:\n",
        "    # API\n",
        "    if task == \"transcribe\" and not detect_language:\n",
        "      api_options['language'] = source_language_code\n",
        "\n",
        "    source_audio_name_path, source_audio_ext = os.path.splitext(audio_path)\n",
        "    source_audio_ext = source_audio_ext[1:]\n",
        "\n",
        "    if source_audio_ext in api_supported_formats:\n",
        "      api_audio_path = audio_path\n",
        "      api_audio_ext = source_audio_ext\n",
        "    else:\n",
        "      ## convert audio file to a supported format\n",
        "      if options['verbose']:\n",
        "        print(f\"API supported formats: {','.join(api_supported_formats)}\")\n",
        "        print(f\"Converting {source_audio_ext} audio to a supported format...\")\n",
        "\n",
        "      api_audio_ext = 'mp3'\n",
        "\n",
        "      api_audio_path = f'{source_audio_name_path}.{api_audio_ext}'\n",
        "\n",
        "      subprocess.run(['ffmpeg', '-i', audio_path, api_audio_path], check=True, capture_output=True)\n",
        "\n",
        "      if options['verbose']:\n",
        "        print(api_audio_path, end='\\n\\n')\n",
        "\n",
        "    ## split audio file in chunks\n",
        "    api_audio_chunks = []\n",
        "\n",
        "    audio_bytes = os.path.getsize(api_audio_path)\n",
        "\n",
        "    if audio_bytes >= api_max_bytes:\n",
        "      if options['verbose']:\n",
        "        print(f\"Audio exceeds API maximum allowed file size.\\nSplitting audio in chunks...\")\n",
        "\n",
        "      audio_segment_file = AudioSegment.from_file(api_audio_path, api_audio_ext)\n",
        "\n",
        "      min_chunks = math.ceil(audio_bytes / (api_max_bytes / 2))\n",
        "\n",
        "      # print(f\"Min chunks: {min_chunks}\")\n",
        "\n",
        "      max_chunk_milliseconds = int(len(audio_segment_file) // min_chunks)\n",
        "\n",
        "      # print(f\"Max chunk milliseconds: {max_chunk_milliseconds}\")\n",
        "\n",
        "      def add_chunk(api_audio_chunk):\n",
        "        api_audio_chunk_path = f\"{source_audio_name_path}_{len(api_audio_chunks) + 1}.{api_audio_ext}\"\n",
        "        api_audio_chunk.export(api_audio_chunk_path, format=api_audio_ext)\n",
        "        api_audio_chunks.append(api_audio_chunk_path)\n",
        "\n",
        "      def raw_split(big_chunk):\n",
        "        subchunks = math.ceil(len(big_chunk) / max_chunk_milliseconds)\n",
        "\n",
        "        for subchunk_i in range(subchunks):\n",
        "          chunk_start = max_chunk_milliseconds * subchunk_i\n",
        "          chunk_end = min(max_chunk_milliseconds * (subchunk_i + 1), len(big_chunk))\n",
        "          add_chunk(big_chunk[chunk_start:chunk_end])\n",
        "\n",
        "      non_silent_chunks = split_on_silence(audio_segment_file,\n",
        "                                           seek_step=5, # ms\n",
        "                                           min_silence_len=1250, # ms\n",
        "                                           silence_thresh=-25, # dB\n",
        "                                           keep_silence=True) # needed to aggregate timestamps\n",
        "\n",
        "      # print(f\"Non silent chunks: {len(non_silent_chunks)}\")\n",
        "\n",
        "      current_chunk = non_silent_chunks[0] if non_silent_chunks else audio_segment_file\n",
        "\n",
        "      for next_chunk in non_silent_chunks[1:]:\n",
        "        if len(current_chunk) > max_chunk_milliseconds:\n",
        "          raw_split(current_chunk)\n",
        "          current_chunk = next_chunk\n",
        "        elif len(current_chunk) + len(next_chunk) <= max_chunk_milliseconds:\n",
        "          current_chunk += next_chunk\n",
        "        else:\n",
        "          add_chunk(current_chunk)\n",
        "          current_chunk = next_chunk\n",
        "\n",
        "      if len(current_chunk) > max_chunk_milliseconds:\n",
        "        raw_split(current_chunk)\n",
        "      else:\n",
        "        add_chunk(current_chunk)\n",
        "\n",
        "      if options['verbose']:\n",
        "        print(f'Total chunks: {len(api_audio_chunks)}\\n')\n",
        "    else:\n",
        "      api_audio_chunks.append(api_audio_path)\n",
        "\n",
        "    ## process chunks\n",
        "    result = None\n",
        "\n",
        "    for api_audio_chunk_path in api_audio_chunks:\n",
        "      ## API request\n",
        "      with open(api_audio_chunk_path, 'rb') as api_audio_file:\n",
        "        api_result = api_transcribe(model=api_model, file=api_audio_file, **api_options)\n",
        "        api_result = api_result.model_dump() # to dict\n",
        "\n",
        "      api_segments = api_result['segments']\n",
        "\n",
        "      if result:\n",
        "        ## update timestamps\n",
        "        last_segment_timestamp = result['segments'][-1]['end'] if result['segments'] else 0\n",
        "\n",
        "        for segment in api_segments:\n",
        "          segment['start'] += last_segment_timestamp\n",
        "          segment['end'] += last_segment_timestamp\n",
        "\n",
        "        ## append new segments\n",
        "        result['segments'].extend(api_segments)\n",
        "\n",
        "        if 'duration' in result:\n",
        "          result['duration'] += api_result.get('duration', 0)\n",
        "      else:\n",
        "        ## first request\n",
        "        result = api_result\n",
        "\n",
        "        if detect_language:\n",
        "          print(f\"Detected language: {result['language'].title()}\\n\")\n",
        "\n",
        "      ## display segments\n",
        "      if options['verbose']:\n",
        "        for segment in api_segments:\n",
        "          print(f\"[{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])}] {segment['text']}\")\n",
        "  else:\n",
        "    # Open-Source\n",
        "    result = whisper.transcribe(model, audio_path, **options)\n",
        "\n",
        "  # fix results formatting\n",
        "  for segment in result['segments']:\n",
        "    segment['text'] = segment['text'].strip()\n",
        "\n",
        "  result['text'] = '\\n'.join(map(lambda segment: segment['text'], result['segments']))\n",
        "\n",
        "  # set results for this audio file\n",
        "  results[audio_path] = result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "pPKHB-83tZB2",
        "outputId": "63c6096b-54cc-4486-d3ce-6d39f71ec72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU ‚ö†Ô∏è\n",
            "Model name: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Not using GPU can result in a very slow execution\n",
            "Ensure Hardware accelerator by GPU is enabled in Google Colab: Runtime > Change runtime type\n",
            "\n",
            "Loading small model... /root/.cache/whisper/small.pt\n",
            "Model small is multilingual and has 240,582,912 parameters.\n",
            "\n",
            "-- TRANSLATE TO ENGLISH --\n",
            "\n",
            "Processing: recording.wav\n",
            "\n",
            "Detected language: German\n",
            "\n",
            "[00:00.000 --> 00:02.000]  How old are you?\n"
          ]
        }
      ]
    }
  ]
}